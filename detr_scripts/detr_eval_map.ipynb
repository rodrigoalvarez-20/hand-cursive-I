{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor, RTDetrImageProcessor, RTDetrForObjectDetection, YolosImageProcessor, YolosForObjectDetection\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torchmetrics.detection import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../hand-cursive-detr\"\n",
    "ANNOTATION_FILE_NAME = \"_val_annotations_coco.json\"\n",
    "#HF_CACHE = \"/home/ralvarez22/Documentos/llm_data/llm_cache\"\n",
    "DEVICE = \"cuda\"\n",
    "CHECKPOINT = \"../finetuned/yolos/Roccia/V_1\"\n",
    "CONFIDENCE_TRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = os.path.join(DATASET_DIR, ANNOTATION_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_json = json.load(open(DATASET_FILE, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_json[\"info\"]\n",
    "del dataset_json[\"licenses\"]\n",
    "del dataset_json[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'annotations'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_boxes = []\n",
    "for e in dataset_json[\"images\"]:\n",
    "    image_annotations = [\n",
    "        x for x in dataset_json[\"annotations\"] if x[\"image_id\"] == e[\"id\"]\n",
    "    ]\n",
    "    images_with_boxes.append(\n",
    "        {\"id\": e[\"id\"], \"image\": e[\"file_name\"], \"boxes\": image_annotations}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MeanAveragePrecision(iou_type=\"bbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_proc = YolosImageProcessor.from_pretrained(CHECKPOINT)\n",
    "detr_model = YolosForObjectDetection.from_pretrained(\n",
    "    pretrained_model_name_or_path=CHECKPOINT, ignore_mismatched_sizes=True\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bboxes(image):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # load image and predict\n",
    "        inputs = detr_proc(images=image, return_tensors='pt').to(DEVICE)\n",
    "        outputs = detr_model(**inputs)\n",
    "\n",
    "        # post-process\n",
    "        target_sizes = torch.tensor([image.shape[:2]]).to(DEVICE)\n",
    "        results = detr_proc.post_process_object_detection(\n",
    "            outputs=outputs, \n",
    "            threshold=CONFIDENCE_TRESHOLD, \n",
    "            target_sizes=target_sizes\n",
    "        )[0]\n",
    "    return results[\"scores\"], results[\"boxes\"], results[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86889e4d0a5a4d0baa42980ccb5be7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/479 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_data = []\n",
    "tgt_data = []\n",
    "for test_item in tqdm(images_with_boxes):\n",
    "    boxes = torch.tensor([ [ x[\"bbox\"][0], x[\"bbox\"][1], x[\"bbox\"][0] + x[\"bbox\"][2], x[\"bbox\"][1] + x[\"bbox\"][3] ]  for x in test_item[\"boxes\"]], device=DEVICE)\n",
    "    cats = torch.tensor([x[\"category_id\"] for x in test_item[\"boxes\"]], device=DEVICE)\n",
    "    input_image = os.path.join(DATASET_DIR, test_item[\"image\"])\n",
    "    image_pixels = cv2.imread(input_image)\n",
    "    scores, pred_boxes, labels = generate_bboxes(image_pixels)\n",
    "    \n",
    "    tgt_data.append({\n",
    "        \"boxes\": boxes,\n",
    "        \"labels\": cats\n",
    "    })\n",
    "    pred_data.append({\n",
    "        \"boxes\": pred_boxes,\n",
    "        \"scores\": scores,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[ 968.2692, 1314.0963, 1018.1793, 1388.9069],\n",
       "         [ 654.6461, 1844.5946,  740.4993, 1928.9562],\n",
       "         [ 124.0910, 1636.5319,  230.3690, 1712.5210],\n",
       "         [ 953.8359, 1992.5837, 1050.0455, 2074.8975],\n",
       "         [ 655.1810, 1996.2584,  743.6088, 2078.9512],\n",
       "         [ 124.1609, 1448.0712,  232.4949, 1526.6598],\n",
       "         [ 496.3203, 1547.2450,  719.8286, 1629.9586],\n",
       "         [ 672.5476, 1632.8647,  929.8230, 1717.1392],\n",
       "         [ 777.8441, 1301.4846,  965.3986, 1378.2616],\n",
       "         [1022.0452,  965.6229, 1078.1942, 1041.1416],\n",
       "         [ 686.5954, 1636.6053,  940.1331, 1709.1573],\n",
       "         [ 358.7355, 1839.5397,  444.8556, 1921.1079],\n",
       "         [1104.0913, 1990.5964, 1204.4180, 2078.1897],\n",
       "         [ 814.6650, 1843.4429,  912.8052, 1928.7087],\n",
       "         [ 496.4165, 1645.8458,  665.7089, 1722.1987],\n",
       "         [1139.5825, 1213.0808, 1195.4320, 1290.7639],\n",
       "         [1033.1924, 1558.0426, 1086.1774, 1633.2048],\n",
       "         [1085.0557,  959.4350, 1250.2191, 1033.1709],\n",
       "         [ 127.2754, 1287.8860,  244.1247, 1366.1927],\n",
       "         [ 780.6844,  950.7230, 1004.8204, 1032.7268],\n",
       "         [ 220.0931, 1835.9601,  315.4055, 1919.0588],\n",
       "         [1395.9750, 1839.0035, 1499.9263, 1926.9609],\n",
       "         [ 130.8147, 1544.4326,  243.2729, 1622.7029],\n",
       "         [ 129.0075, 1199.5541,  242.6837, 1276.3431],\n",
       "         [1157.0776,  860.2101, 1219.2555,  939.5994],\n",
       "         [ 507.8219,  950.4253,  773.6404, 1031.3152],\n",
       "         [ 212.6486, 1988.9329,  303.6591, 2072.4236],\n",
       "         [ 116.6027,  849.8668,  235.0331,  925.3927],\n",
       "         [1391.8340, 1995.2872, 1508.1619, 2080.4976],\n",
       "         [ 502.5063, 1991.8203,  609.2338, 2074.2544],\n",
       "         [ 809.9185, 1996.6201,  905.5792, 2083.0984],\n",
       "         [ 106.7985,  759.2316,  230.6471,  835.0822],\n",
       "         [ 507.5631, 1841.4922,  596.2583, 1924.7389],\n",
       "         [ 126.8439, 1105.0642,  246.7363, 1180.3645],\n",
       "         [ 123.4580,  941.3936,  246.5778, 1017.5289],\n",
       "         [ 867.2100, 1205.0001, 1129.6013, 1288.1847],\n",
       "         [ 862.5469,  857.6182, 1139.9612,  942.0577],\n",
       "         [ 877.1347,   57.2094, 1022.4464,  112.4422],\n",
       "         [1021.1212, 1303.6473, 1168.4877, 1378.8041],\n",
       "         [1196.9396, 1207.3147, 1397.6704, 1286.3540],\n",
       "         [ 471.0073,   44.1864,  538.5004,   97.2110],\n",
       "         [1250.6986, 1990.4502, 1345.1166, 2076.9470],\n",
       "         [ 501.4323,  849.9537,  854.3169,  934.2154],\n",
       "         [1225.5450,  860.5226, 1431.8164,  939.3943],\n",
       "         [1003.7060, 1651.6611, 1120.3997, 1724.5013],\n",
       "         [ 504.2457, 1294.9271,  774.0260, 1374.7015],\n",
       "         [ 360.8037, 1987.7396,  452.8483, 2070.2917],\n",
       "         [ 944.4125, 1652.5291, 1003.2929, 1732.0662],\n",
       "         [1070.0105, 1553.8721, 1235.1171, 1632.5065],\n",
       "         [1099.0217, 1839.9972, 1200.8109, 1925.5908],\n",
       "         [1254.2368, 1842.5518, 1348.0670, 1927.4998],\n",
       "         [ 719.1480, 1547.9451, 1019.1436, 1630.1571],\n",
       "         [ 505.9778, 1199.7257,  865.0255, 1284.0441],\n",
       "         [ 959.5918, 1843.6088, 1055.3477, 1927.8573]], device='cuda:0'),\n",
       " 'scores': tensor([0.9996, 0.9989, 0.9991, 0.9996, 0.9968, 0.9999, 0.9999, 0.7839, 0.9999,\n",
       "         0.9996, 0.7928, 0.9999, 0.9990, 0.9990, 0.9994, 0.9997, 0.9997, 0.9997,\n",
       "         0.9999, 0.9999, 1.0000, 0.9995, 1.0000, 0.9998, 0.9974, 1.0000, 0.9996,\n",
       "         1.0000, 0.9995, 0.9997, 0.9984, 1.0000, 0.9998, 1.0000, 1.0000, 0.9992,\n",
       "         0.9991, 0.9997, 0.9999, 0.9998, 0.9998, 0.9998, 0.9993, 0.9998, 0.9992,\n",
       "         1.0000, 0.9999, 0.9998, 0.9993, 0.9991, 0.9997, 0.9998, 0.9998, 0.9988],\n",
       "        device='cuda:0'),\n",
       " 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[ 495., 1560.,  713., 1640.],\n",
       "         [ 497.,  861.,  845.,  929.],\n",
       "         [1250., 1852., 1339., 1931.],\n",
       "         [1392., 1997., 1507., 2081.],\n",
       "         [ 657., 2001.,  745., 2078.],\n",
       "         [ 522., 1294.,  768., 1371.],\n",
       "         [ 665., 1649.,  917., 1725.],\n",
       "         [ 134., 1449.,  236., 1524.],\n",
       "         [ 125.,  941.,  238., 1014.],\n",
       "         [1001., 1659., 1106., 1726.],\n",
       "         [ 216., 1992.,  311., 2074.],\n",
       "         [1198., 1215., 1390., 1290.],\n",
       "         [ 511., 1996.,  621., 2076.],\n",
       "         [ 223., 1844.,  315., 1922.],\n",
       "         [1084., 1567., 1249., 1643.],\n",
       "         [ 128., 1109.,  243., 1181.],\n",
       "         [ 367., 1843.,  447., 1921.],\n",
       "         [ 368., 1991.,  459., 2070.],\n",
       "         [1244., 1995., 1341., 2077.],\n",
       "         [ 106.,  765.,  228.,  838.],\n",
       "         [1084.,  956., 1242., 1029.],\n",
       "         [1153.,  852., 1208.,  934.],\n",
       "         [1015.,  953., 1069., 1030.],\n",
       "         [ 663., 1847.,  739., 1931.],\n",
       "         [ 956., 1996., 1040., 2077.],\n",
       "         [ 527., 1206.,  849., 1284.],\n",
       "         [ 847., 1204., 1122., 1285.],\n",
       "         [ 768., 1301.,  971., 1376.],\n",
       "         [ 958., 1845., 1048., 1929.],\n",
       "         [ 114.,  850.,  233.,  923.],\n",
       "         [ 131., 1205.,  240., 1279.],\n",
       "         [1020., 1316., 1163., 1377.],\n",
       "         [1217.,  861., 1423.,  940.],\n",
       "         [ 813., 2001.,  903., 2082.],\n",
       "         [1391., 1846., 1500., 1931.],\n",
       "         [1097., 1851., 1197., 1931.],\n",
       "         [ 869.,  853., 1137.,  936.],\n",
       "         [ 133., 1644.,  228., 1718.],\n",
       "         [ 140., 1546.,  249., 1618.],\n",
       "         [ 776.,  949.,  996., 1027.],\n",
       "         [ 815., 1851.,  912., 1932.],\n",
       "         [1132., 1215., 1186., 1289.],\n",
       "         [ 723., 1545.,  997., 1627.],\n",
       "         [ 129., 1294.,  241., 1369.],\n",
       "         [1101., 1995., 1197., 2079.],\n",
       "         [ 517., 1846.,  600., 1926.],\n",
       "         [ 513.,  955.,  769., 1027.],\n",
       "         [ 474.,   39.,  543.,   99.],\n",
       "         [ 882.,   58., 1019.,  109.],\n",
       "         [1026., 1567., 1080., 1628.],\n",
       "         [ 944., 1664.,  995., 1736.],\n",
       "         [ 498., 1657.,  660., 1725.],\n",
       "         [ 970., 1339., 1019., 1400.]], device='cuda:0'),\n",
       " 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.update(pred_data, tgt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'map': tensor(0.5878),\n",
       " 'map_50': tensor(0.9623),\n",
       " 'map_75': tensor(0.6584),\n",
       " 'map_small': tensor(0.),\n",
       " 'map_medium': tensor(0.5173),\n",
       " 'map_large': tensor(0.6345),\n",
       " 'mar_1': tensor(0.0137),\n",
       " 'mar_10': tensor(0.1291),\n",
       " 'mar_100': tensor(0.6702),\n",
       " 'mar_small': tensor(0.),\n",
       " 'mar_medium': tensor(0.6057),\n",
       " 'mar_large': tensor(0.7119),\n",
       " 'map_per_class': tensor(-1.),\n",
       " 'mar_100_per_class': tensor(-1.),\n",
       " 'classes': tensor(1, dtype=torch.int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyFormers + CUDA",
   "language": "python",
   "name": "dev-kernel-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
