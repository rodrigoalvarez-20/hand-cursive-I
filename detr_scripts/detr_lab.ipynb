{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETR Test Lab Nootebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows to test the base model and finetuned model of DETR\n",
    "\n",
    "First load the model to CUDA and, with a given image, the model tries to generate the bounding boxes for only the match text.\n",
    "\n",
    "The main purpose of this is to crop the base image with the generated boxes and pass the cropped images to the TROCR to recognize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "import torch\n",
    "import cv2\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"../finetuned/detr/Nous/V_3\"\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_proc = DetrImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "detr_model = DetrForObjectDetection.from_pretrained(\n",
    "    pretrained_model_name_or_path=MODEL_CHECKPOINT,\n",
    "    num_queries=100,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_TRESHOLD = 0.8 # This parameter allows to filter the generated boxes with a confidence score >= to this value\n",
    "IOU_TRESHOLD = 0.1\n",
    "TEST_IMAGE = \"../hand-cursive-detr/test_samples/test_image_detr_1.jpeg\" # Path to the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the pixel values of the image (matrix)\n",
    "image = cv2.imread(TEST_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "with torch.inference_mode():\n",
    "    # load image and predict\n",
    "    inputs = img_proc(images=image, return_tensors='pt').to(DEVICE)\n",
    "    outputs = detr_model(**inputs)\n",
    "    # post-process\n",
    "    # Resize the generated Bounding Boxes coords to the image original size\n",
    "    target_sizes = torch.tensor([image.shape[:2]]).to(DEVICE)\n",
    "    results = img_proc.post_process_object_detection(\n",
    "        outputs=outputs, \n",
    "        threshold=CONFIDENCE_TRESHOLD, \n",
    "        target_sizes=target_sizes\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[\"boxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With supervision lib, use the generated coords to annotate the image and preview the boxes\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "detections = sv.Detections.from_transformers(transformers_results=results).with_nms(threshold=IOU_TRESHOLD)\n",
    "labels = [f\"{confidence:.2f} - {class_id}\" for _,_, confidence, class_id,_,_, in detections]\n",
    "frame = box_annotator.annotate(scene=image.copy(), detections=detections)\n",
    "\n",
    "#print('detections')\n",
    "%matplotlib inline  \n",
    "sv.plot_image(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyFormers + CUDA",
   "language": "python",
   "name": "dev-kernel-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
