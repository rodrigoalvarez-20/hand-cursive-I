{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DS_PATH = \"detr_app_dataset/train\"\n",
    "DS_FILE = \"_annotations.coco.json\"\n",
    "TRAIN_PATH = \"hand-cursive-detr/train\"\n",
    "VAL_PATH = \"hand-cursive-detr/valid\"\n",
    "DATASE_FILE_OUT = \"hand-cursive-detr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_data = json.load(open(os.path.join(ORIGINAL_DS_PATH, DS_FILE), \"r\", encoding=\"utf-8\"))\n",
    "dataset_images = dataset_data[\"images\"]\n",
    "len(dataset_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_items = math.floor(len(dataset_images) * 0.7)\n",
    "selected_train_images = dataset_images[:total_train_items]\n",
    "selected_val_images = dataset_images[total_train_items:]\n",
    "len(selected_train_images), len(selected_val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = {\n",
    "    \"info\": dataset_data[\"info\"],\n",
    "    \"licenses\": dataset_data[\"licenses\"],\n",
    "    \"categories\": dataset_data[\"categories\"],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "for idx, image in enumerate(tqdm(selected_train_images)):\n",
    "    annotations_from_image = [ x for x in dataset_data[\"annotations\"] if x[\"image_id\"] == image[\"id\"] ]\n",
    "    annotations_from_image = [ {**x, \"image_id\": idx, \"id\": uuid4().hex[:12]} for x in annotations_from_image ]\n",
    "    selected_image = { **image }\n",
    "    selected_image[\"id\"] = idx\n",
    "    dst_path = os.path.join(TRAIN_PATH, selected_image[\"file_name\"])\n",
    "    shutil.copyfile(os.path.join(ORIGINAL_DS_PATH, selected_image[\"file_name\"]), dst_path)\n",
    "    selected_image[\"file_name\"] = os.path.join(\"train\", selected_image[\"file_name\"])\n",
    "    train_dataset[\"images\"].append(selected_image)\n",
    "    train_dataset[\"annotations\"] += annotations_from_image\n",
    "    \n",
    "train_dataset[\"annotations\"] = [ {**x, \"id\": idx} for idx, x in enumerate(train_dataset[\"annotations\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = {\n",
    "    \"info\": dataset_data[\"info\"],\n",
    "    \"licenses\": dataset_data[\"licenses\"],\n",
    "    \"categories\": dataset_data[\"categories\"],\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "for idx, image in enumerate(tqdm(selected_val_images)):\n",
    "    annotations_from_image = [ x for x in dataset_data[\"annotations\"] if x[\"image_id\"] == image[\"id\"] ]\n",
    "    annotations_from_image = [ {**x, \"image_id\": idx, \"id\": uuid4().hex[:12]} for x in annotations_from_image ]\n",
    "    selected_image = { **image }\n",
    "    selected_image[\"id\"] = idx\n",
    "    dst_path = os.path.join(VAL_PATH, selected_image[\"file_name\"])\n",
    "    shutil.copyfile(os.path.join(ORIGINAL_DS_PATH, selected_image[\"file_name\"]), dst_path)\n",
    "    selected_image[\"file_name\"] = os.path.join(\"valid\", selected_image[\"file_name\"])\n",
    "    val_dataset[\"images\"].append(selected_image)\n",
    "    val_dataset[\"annotations\"] += annotations_from_image\n",
    "val_dataset[\"annotations\"] = [ {**x, \"id\": idx} for idx, x in enumerate(val_dataset[\"annotations\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(train_dataset, open(os.path.join(DATASE_FILE_OUT, \"_train_annotations_coco.json\"), \"w\", encoding=\"utf-8\"))\n",
    "json.dump(val_dataset, open(os.path.join(DATASE_FILE_OUT, \"_val_annotations_coco.json\"), \"w\", encoding=\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyFormers + CUDA",
   "language": "python",
   "name": "dev-kernel-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
